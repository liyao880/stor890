---
title: '**STOR 890: Trustworthy Machine Learning**'
geometry: margin=2
output:
  prettydoc::html_pretty:
    theme: cayman
    css: custom.css
  html_document:
    toc: yes
    df_print: paged
  pdf_document:
    toc: yes
---



# **About the Course**

See the **[syllabus](Syllabi/890_Syllabus.pdf)** for details. This topics course is designed for graduate students who are interested in the emerging area of AI security and trustworthy machine learning. Modern machine learning systems are increasingly deployed in high-stakes applications, making it essential to understand their vulnerabilities, limitations, and the principles needed to ensure reliability. The goal of this course is to help students develop a solid conceptual and practical foundation in the security and trustworthiness aspects of machine learning by studying core threat models, analyzing state-of-the-art research papers, and working on research-oriented projects. 


- Instructor: **[Yao Li](https://liyao880.github.io/yaoli/)**

- Class: TTH 8:00AM-9:15AM, Hanes 125

- Office Hours: TH 9:30AM-10:30AM, Hanes 334


# **Course Material**

| Date | Topic | Paper Link| Slides|
|:-----:|:------------------|:--------:|:-------:|
|Jan. 08| Logistics and Overview | | [S1](https://drive.google.com/file/d/1qkf-3g5ZQOv_aBEeEKMQncWlBQ4ilwY7/view?usp=sharing) [S2](https://drive.google.com/file/d/1FBtdqSABPwhnW8sXwCVXbe-lmYKvdD5J/view?usp=sharing)|
|Jan. 13| MLP and CNN | | <a href="#" class="protected-link" data-url="https://drive.google.com/file/d/1EAZo74e5mKA8tqSPX-c0gQfckUqGuJdK/view?usp=sharing">S1</a> <a href="#" class="protected-link" data-url="https://drive.google.com/file/d/15Od7Kzat6ICSj-DPSP-G_8Q0z3dZubmV/view?usp=sharing">S2</a>|
|Jan. 15| RNN | | <a href="#" class="protected-link" data-url="https://drive.google.com/file/d/1A0ZFIdQ07nfSD0mfNs8FQlgzlvIJjWZe/view?usp=sharing">S1</a> <a href="#" class="protected-link" data-url="https://drive.google.com/file/d/10uQj5O9IXZ9bht2OQZTmgP1yMYdpLYlr/view?usp=sharing">S2</a>|
|Jan. 20| Transformer | | |
|Jan. 22| Travel (Class Cancel) | | |
|Jan. 27| Generative models  | | |
|Jan. 29| LLM | | |
|Feb. 03| Backdoor attack| [P1](https://arxiv.org/abs/1708.06733)     [P2](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Invisible_Backdoor_Attack_With_Sample-Specific_Triggers_ICCV_2021_paper.pdf) | |
|Feb. 05| Backdoor defense |[P1](https://arxiv.org/abs/2310.01875)   [P2](https://ieeexplore.ieee.org/document/11121441) | |
|Feb. 10| Federated learning |[P1](https://icml.cc/virtual/2022/spotlight/18208)   [P2](https://openreview.net/pdf?id=r9eNUDe2im) | |
|Feb. 12| Adversarial attack |[P1](https://arxiv.org/abs/1608.04644)   [P2](https://openreview.net/pdf?id=SyZI0GWCZ) | |
|Feb. 17| Project Proposal Discussion || |
|Feb. 19| Project Proposal Discussion || |
|Feb. 24| Adversarial defense |[P1](https://arxiv.org/pdf/1706.06083.pdf)   [P2](https://arxiv.org/pdf/2001.03994.pdf)| |
|Feb. 26| Privacy attacks | [P1](https://arxiv.org/abs/1610.05820.pdf)   [P2](https://openaccess.thecvf.com/content/CVPR2022/papers/Kahla_Label-Only_Model_Inversion_Attacks_via_Boundary_Repulsion_CVPR_2022_paper.pdf)| |
|Mar. 03| Explainable AI |[P1](https://arxiv.org/abs/1610.02391.pdf)   [P2](https://proceedings.neurips.cc/paper_files/paper/2024/file/48dfc849640344e2d58df0b5bb78c33b-Paper-Conference.pdf) | |
|Mar. 05| Fairness  |[P1](https://science.sciencemag.org/content/356/6334/183)   [P2](https://arxiv.org/pdf/2410.19803)| |
|Mar. 10| Watermark LLM |[P1](https://arxiv.org/pdf/2301.10226)   [P2](https://arxiv.org/pdf/2510.03944)| |
|Mar. 12| Jailbreak attack | [P1](https://arxiv.org/pdf/2307.15043)   [P2](https://arxiv.org/pdf/2310.03693)| |
|Mar. 17| Spring Break || |
|Mar. 19| Spring Break | | |
|Mar. 24| Midpoint Project Review | | |
|Mar. 26| Midpoint Project Review | | |
|Mar. 31| Jailbreak defense | [P1](https://aclanthology.org/2024.acl-long.568.pdf)   [P2](https://arxiv.org/pdf/2402.08983)| |
|Apr. 02| Well-being Day | | |
|Apr. 07| Backdoor in LLM | [P1](https://arxiv.org/pdf/2401.05566)   [P2](https://arxiv.org/pdf/2311.09433)| |
|Apr. 09| Backdoor defense in LLM|[P1](https://arxiv.org/pdf/2306.05685)   [P2](https://arxiv.org/pdf/2405.07667)| |
|Apr. 14| Hallucination |[P1](https://www.nature.com/articles/s41586-024-07421-0)   [P2](https://iclr.cc/virtual/2025/poster/29377)| |
|Apr. 16| Safety alignment |[P1](https://icml.cc/virtual/2025/poster/44803)   [P2](https://iclr.cc/virtual/2025/poster/30893)| |
|Apr. 21| Final Presentation || |
|Apr. 23| Final Presentation || |


# **Class Participation**

Use the **[participation record](https://docs.google.com/spreadsheets/d/17Y-TwH-TYV16H02UKJ8Y0oajadhFZ-jTOfCyb0f9nQA/edit?usp=sharing)** to report class participation. 


# **Paper Presentation**

Each student will present **one or two research papers** during the semester, depending on enrollment. You can use the **[paper list](https://docs.google.com/spreadsheets/d/1cVQau07hlNPvOZCd08GkHqdNLAE9le8EKT9fK0gYwIU/edit?usp=sharing)** to sign up for your preferred papers.

- **Before January 18:**  
  Students may freely sign up for available papers using the shared spreadsheet. Please sign up for **two papers** unless instructed otherwise.

- **After January 18:**  
  Any papers that remain unassigned will be **randomly allocated** to students by the instructor, or the instructor will present them. These assignments will be final.

Slides must be uploaded **by 11:59pm the night before class** on the day of your presentation. Late submissions will incur penalties.



# **Final Project Details**

This course includes a final project in lieu of a final exam. Projects may be completed individually or in groups of two. Groups of more than two are not permitted. The final project consists of:

- Project Proposal (10%)
- Project Presentation (40%)
- Project Paper (50%)


## Three Parts Including Point Values

I will meet with each student or group to discuss potential project topics. Suitable topics include, but are not limited to:

- Conducting a careful empirical study comparing state-of-the-art methods;
- Reproducing an influential research paper and analyzing its limitations;
- Developing a small methodological or algorithmic extension;
- A structured survey of a focused sub-area in trustworthy machine learning.
- ...
    
**P1: Project Proposal** *(10 Points):* The project proposal is limited to 2-page (excluding reference) and contains:

- The problem you aim to address;
- A brief review of related work;
- The method(s) you plan to use or compare;
- Evaluation metrics and expected outcomes;
- Reference.

See latex template at [link](https://drive.google.com/file/d/16uQ-fbVysshhh13xvnpNy5GYPAMcplDK/view?usp=sharing).


**P2: Project Presentation** *(40 Points):* Presentations will take place during the final 2 - 3 lectures of the semester. Each student or group will give a short presentation (length announced later) summarizing the problem, approach, results, and conclusions. Attendance is required for all presentations.


**P3: Project Paper** *(50 Points):* Students must submit a written final report in PDF format. The report must use the [NeurIPS Latex style files](https://media.neurips.cc/Conferences/NeurIPS2025/Styles.zip) and should be no more than 8 pages excluding references (there is no minimum length requirement). The report may include a discussion of possible future extensions.



    
## Due Dates of Individual Parts

| Part | Description |Location| Due Date (Time) |
|----|-------------|---------------------|---------------:|
| P1  | Project Proposal | Canvas | Feb. 15 (11:59PM)|
|   | Proposal Meeting | Hanes 334 | Feb. 17 / Feb. 19 (Lecture Time)|
| P2  | Presentation Slides |Canvas| Apr. 20 / Apr. 22 (11:59PM)|
|   | Final Presentation|Class| Apr. 21 / Apr. 23 (Lecture time)|
| P3  | Final Report|Canvas|Apr. 30 (11:59PM)|






This page was last updated on `r Sys.time()` Eastern Time.

<script>
  document.addEventListener("DOMContentLoaded", function() {
    const correctPassword = "hanes890"; // Set your password here
    const links = document.getElementsByClassName("protected-link");

    for (let i = 0; i < links.length; i++) {
      links[i].addEventListener("click", function(event) {
        event.preventDefault(); // Prevent the default action of the link
        const userPassword = prompt("Enter the password to access this link:");
        if (userPassword === correctPassword) {
          window.open(this.getAttribute("data-url"), "_blank"); // Open the link in a new tab
        } else {
          alert("Incorrect password. Access denied.");
        }
      });
    }
  });
</script>
